{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3J06UmvQpzJyjAZKgL3gO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -qU langchain langchain-google-genai pymupdf python-docx scikit-learn"],"metadata":{"id":"5bYA1HxUugVV","executionInfo":{"status":"ok","timestamp":1764601565307,"user_tz":-420,"elapsed":8627,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Imports\n","import os\n","import json\n","from typing import Dict, Any\n","\n","# LangChain + Google GenAI\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","# Document processing\n","import fitz  # PyMuPDF\n","from docx import Document\n","\n","# ML models\n","from sklearn.dummy import DummyClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","\n","# Embedder model from huggingface\n","from sentence_transformers import SentenceTransformer\n","from getpass import getpass"],"metadata":{"id":"qkR0DOmsFgok","executionInfo":{"status":"ok","timestamp":1764603704131,"user_tz":-420,"elapsed":19,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# For file upload in Colab\n","try:\n","    from google.colab import files\n","    IN_COLAB = True\n","except Exception:\n","    IN_COLAB = False"],"metadata":{"id":"EPTYeXq3IGFt","executionInfo":{"status":"ok","timestamp":1764601565354,"user_tz":-420,"elapsed":4,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Global config\n","GEMINI_MODEL = \"gemini-2.5-flash\"\n","GEMINI_API_KEY = getpass('ENTER GEMINI API KEY: ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y51FjEOpWs4e","executionInfo":{"status":"ok","timestamp":1764603222429,"user_tz":-420,"elapsed":1497,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}},"outputId":"fcd57a50-8ae9-40bb-b530-e67b8ca72c09"},"execution_count":53,"outputs":[{"name":"stdout","output_type":"stream","text":["ENTER GEMINI API KEY: ··········\n"]}]},{"cell_type":"code","source":["# Embedder\n","EMBED_MODEL_NAME = \"all-MiniLM-L6-v2\"\n","embedder = SentenceTransformer(EMBED_MODEL_NAME)"],"metadata":{"id":"IIlNINoHarMt","executionInfo":{"status":"ok","timestamp":1764603384951,"user_tz":-420,"elapsed":2385,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["def scrape_pdf_with_gemini(file_path: str, api_key: str) -> str:\n","    \"\"\"Use Gemini to extract and structure text from PDF.\"\"\"\n","    # configure API key\n","    os.environ['GOOGLE_API_KEY'] = api_key\n","\n","    # first extract text using PyMuPDF\n","    doc = fitz.open(file_path)\n","    extracted_text = \"\"\n","    for page in doc:\n","        extracted_text += page.get_text()\n","    doc.close()\n","\n","    # Then use Gemini to clean and structure the text\n","    llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=0.0)\n","\n","    prompt = f\"\"\"\n","    The following is raw text extracted from a PDF resume/CV document.\n","    Please clean, organize, and structure this text properly.\n","    Preserve all information but make it well-formatted and readable.\n","    Include all sections like contact info, summary, experience, education, skills, etc.\n","\n","    Raw text:\n","    {extracted_text}\n","    \"\"\"\n","\n","    response = llm.invoke(prompt)\n","    return response.content\n","\n","def scrape_docx_with_gemini(file_path: str, api_key: str) -> str:\n","    \"\"\"Use Gemini to extract and structure text from DOCX.\"\"\"\n","    # Configure API key\n","    os.environ['GOOGLE_API_KEY'] = api_key\n","\n","    # First extract text using python-docx\n","    doc = Document(file_path)\n","    extracted_text = \"\\n\\n\".join([paragraph.text for paragraph in doc.paragraphs if paragraph.text.strip()])\n","\n","    # Then use Gemini to clean and structure the text\n","    llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=0.0)\n","\n","    prompt = f\"\"\"\n","    The following is raw text extracted from a DOCX resume/CV document.\n","    Please clean, organize, and structure this text properly.\n","    Preserve all information but make it well-formatted and readable.\n","    Include all sections like contact info, summary, experience, education, skills, etc.\n","\n","    Raw text:\n","    {extracted_text}\n","    \"\"\"\n","\n","    response = llm.invoke(prompt)\n","    return response.content"],"metadata":{"id":"Rg3zhxJSFkT0","executionInfo":{"status":"ok","timestamp":1764601566580,"user_tz":-420,"elapsed":15,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# TODO: REPLACE WITH ACTUAL BUILDED MODELS\n","class ResumeModels:\n","    \"\"\"Container for your trained models.\"\"\"\n","\n","    def __init__(self):\n","        # Initialize placeholder models\n","        self.role_pipeline = self._init_role_model()\n","        self.acceptance_pipeline = self._init_acceptance_model()\n","\n","    def _init_role_model(self):\n","        \"\"\"Initialize role prediction model (replace with your trained model).\"\"\"\n","        role_vectorizer = TfidfVectorizer(max_features=2000)\n","        role_clf = DummyClassifier(strategy=\"most_frequent\")\n","        pipeline = Pipeline([('tfidf', role_vectorizer), ('clf', role_clf)])\n","\n","        # Train on sample data (replace with your real model loading)\n","        X_sample = [\n","            \"Experienced backend engineer with python, django, rest apis\",\n","            \"Junior frontend developer skilled in react, javascript, css\",\n","            \"Data scientist with experience in sklearn, pandas, ml models\",\n","        ]\n","        y_sample = [\"Backend Engineer\", \"Frontend Engineer\", \"Data Scientist\"]\n","        pipeline.fit(X_sample, y_sample)\n","\n","        return pipeline\n","\n","    def _init_acceptance_model(self):\n","        \"\"\"Initialize acceptance prediction model (replace with your trained model).\"\"\"\n","        accept_vectorizer = TfidfVectorizer(max_features=2000)\n","        accept_clf = DummyClassifier(strategy=\"stratified\")\n","        pipeline = Pipeline([('tfidf', accept_vectorizer), ('clf', accept_clf)])\n","\n","        # Train on sample data (replace with your real model loading)\n","        X_sample = [\n","            \"Experienced backend engineer with python, django, rest apis\",\n","            \"Junior frontend developer skilled in react, javascript, css\",\n","            \"Data scientist with experience in sklearn, pandas, ml models\",\n","        ]\n","        y_sample = [1, 0, 1]\n","        pipeline.fit(X_sample, y_sample)\n","\n","        return pipeline\n","\n","    def predict_role(self, resume_text: str) -> str:\n","        \"\"\"Predict job role from resume text.\"\"\"\n","        try:\n","            pred = self.role_pipeline.predict([resume_text])[0]\n","            return str(pred)\n","        except Exception as e:\n","            # Fallback heuristic\n","            text_lower = resume_text.lower()\n","            if \"data\" in text_lower or \"machine learning\" in text_lower:\n","                return \"Data Scientist\"\n","            elif \"react\" in text_lower or \"frontend\" in text_lower:\n","                return \"Frontend Engineer\"\n","            else:\n","                return \"Backend Engineer\"\n","\n","    def predict_acceptance(self, resume_text: str) -> float:\n","        \"\"\"Predict acceptance probability (0-1).\"\"\"\n","        try:\n","            prob = self.acceptance_pipeline.predict_proba([resume_text])[0]\n","            if len(prob) == 2:\n","                return float(prob[1])\n","            return float(prob.max())\n","        except Exception as e:\n","            # Fallback heuristic\n","            keywords = [\"experienced\", \"senior\", \"lead\", \"machine learning\", \"phd\", \"master\"]\n","            score = sum([1 for k in keywords if k in resume_text.lower()]) / len(keywords)\n","            return float(score)"],"metadata":{"id":"GZOHP7maG8fH","executionInfo":{"status":"ok","timestamp":1764602106155,"user_tz":-420,"elapsed":21,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["def compute_resume_jd_similarity(resume_text: str, jd_text: str) -> Dict[str, Any]:\n","    \"\"\"\n","    Compute similarity between resume and job description using embeddings.\n","    Uses the embedder (all-MiniLM-L6-v2).\n","    \"\"\"\n","    # Get embeddings from your separate embedder module\n","    texts = [resume_text, jd_text]\n","    embeddings = embedder.encode(texts, show_progress_bar=False)\n","\n","    resume_vec = embeddings[0]\n","    jd_vec = embeddings[1]\n","\n","    # Cosine similarity\n","    cosine_sim = np.dot(resume_vec, jd_vec) / (\n","        np.linalg.norm(resume_vec) * np.linalg.norm(jd_vec) + 1e-9\n","    )\n","\n","    # Find missing keywords\n","    jd_tokens = set(jd_text.lower().split())\n","    resume_tokens = set(resume_text.lower().split())\n","    missing_keywords = list(jd_tokens - resume_tokens)[:20]\n","\n","    return {\n","        'similarity_score': float(cosine_sim),\n","        'missing_keywords': missing_keywords\n","    }"],"metadata":{"id":"_ncLkHoNHCUR","executionInfo":{"status":"ok","timestamp":1764602125383,"user_tz":-420,"elapsed":23,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["def get_gemini_assessment(\n","    resume_text: str,\n","    jd_text: str,\n","    predicted_role: str,\n","    acceptance_prob: float,\n","    similarity_score: float,\n","    missing_keywords: list,\n","    api_key: str\n",") -> Dict[str, Any]:\n","    \"\"\"\n","    Send all model outputs to Gemini for final scoring and revision recommendations.\n","    \"\"\"\n","    # Configure API key\n","    os.environ['GOOGLE_API_KEY'] = api_key\n","\n","    llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=0.0)\n","\n","    prompt = f\"\"\"\n","You are an expert resume/CV reviewer and career consultant.\n","\n","I have analyzed a resume using ML models and need your expert assessment and recommendations.\n","\n","**Resume Text:**\n","{resume_text[:3000]}\n","\n","**Job Description:**\n","{jd_text}\n","\n","**ML Model Analysis Results:**\n","- Predicted Role: {predicted_role}\n","- Acceptance Probability: {acceptance_prob:.2%}\n","- Resume-JD Similarity Score: {similarity_score:.3f} (0-1 scale, based on semantic embeddings)\n","- Missing Keywords from JD: {', '.join(missing_keywords[:15])}\n","\n","**Your Task:**\n","Based on the resume, job description, and ML model outputs, provide:\n","\n","1. **Overall Score (0-100)**: A numerical score indicating how well this resume matches the job\n","2. **Score Explanation**: 2-3 sentences explaining the score\n","3. **Strengths**: 2-3 key strengths of this resume for this role\n","4. **Weaknesses**: 2-3 key weaknesses or gaps\n","5. **Revision Suggestions**: 5-7 specific, actionable suggestions to improve the resume (be concrete)\n","6. **Keyword Recommendations**: Specific keywords/skills to add based on missing keywords\n","7. **Summary Rewrite**: A suggested 2-3 sentence professional summary optimized for this role\n","8. **ATS Optimization Tips**: 2-3 tips to improve ATS (Applicant Tracking System) compatibility\n","\n","Return your response in valid JSON format with these exact keys:\n","{{\n","  \"score\": <number 0-100>,\n","  \"explanation\": \"<string>\",\n","  \"strengths\": [\"<string>\", \"<string>\", ...],\n","  \"weaknesses\": [\"<string>\", \"<string>\", ...],\n","  \"revision_suggestions\": [\"<string>\", \"<string>\", ...],\n","  \"keyword_recommendations\": [\"<string>\", \"<string>\", ...],\n","  \"summary_rewrite\": \"<string>\",\n","  \"ats_tips\": [\"<string>\", \"<string>\", ...]\n","}}\n","\"\"\"\n","\n","    response = llm.invoke(prompt)\n","\n","    try:\n","        # Extract JSON from response\n","        response_text = response.content.strip()\n","        # Remove markdown code blocks if present\n","        if response_text.startswith('```'):\n","            response_text = response_text.split('```')[1]\n","            if response_text.startswith('json'):\n","                response_text = response_text[4:]\n","            response_text = response_text.rsplit('```', 1)[0]\n","\n","        assessment = json.loads(response_text)\n","        return assessment\n","    except json.JSONDecodeError:\n","        # Fallback if JSON parsing fails\n","        return {\n","            'score': 0,\n","            'explanation': 'Error parsing Gemini response',\n","            'raw_response': response.content\n","        }"],"metadata":{"id":"lSzIJzXKHI8t","executionInfo":{"status":"ok","timestamp":1764601566638,"user_tz":-420,"elapsed":6,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def analyze_resume(\n","    resume_file_path: str,\n","    job_description: str,\n","    api_key: str\n",") -> Dict[str, Any]:\n","    \"\"\"\n","    Complete resume analysis pipeline.\n","\n","    Steps:\n","    1. Gemini scrapes the resume file\n","    2. Your models analyze the resume\n","    3. Embedder computes similarity\n","    4. Gemini provides final assessment and recommendations\n","    \"\"\"\n","\n","    print(\"Step 1: Extracting text from resume using Gemini...\")\n","    # Scrape resume with Gemini\n","    if resume_file_path.lower().endswith('.pdf'):\n","        resume_text = scrape_pdf_with_gemini(resume_file_path, api_key)\n","    elif resume_file_path.lower().endswith('.docx'):\n","        resume_text = scrape_docx_with_gemini(resume_file_path, api_key)\n","    else:\n","        raise ValueError(\"File must be PDF or DOCX\")\n","\n","    print(\"Step 2: Running your ML models...\")\n","    # Initialize your models\n","    models = ResumeModels()\n","\n","    # Get predictions from your models\n","    predicted_role = models.predict_role(resume_text)\n","    acceptance_prob = models.predict_acceptance(resume_text)\n","\n","    print(\"Step 3: Computing embedding similarity...\")\n","    # Compute similarity using your embedder\n","    similarity_result = compute_resume_jd_similarity(resume_text, job_description)\n","\n","    print(\"Step 4: Getting Gemini assessment and recommendations...\")\n","    # Get final assessment from Gemini\n","    gemini_assessment = get_gemini_assessment(\n","        resume_text=resume_text,\n","        jd_text=job_description,\n","        predicted_role=predicted_role,\n","        acceptance_prob=acceptance_prob,\n","        similarity_score=similarity_result['similarity_score'],\n","        missing_keywords=similarity_result['missing_keywords'],\n","        api_key=api_key\n","    )\n","\n","    # Compile final results\n","    results = {\n","        'resume_text': resume_text,\n","        'model_outputs': {\n","            'predicted_role': predicted_role,\n","            'acceptance_probability': acceptance_prob,\n","            'similarity_score': similarity_result['similarity_score'],\n","            'missing_keywords': similarity_result['missing_keywords']\n","        },\n","        'gemini_assessment': gemini_assessment\n","    }\n","\n","    return results"],"metadata":{"id":"ISjX-MZvHWlQ","executionInfo":{"status":"ok","timestamp":1764601566658,"user_tz":-420,"elapsed":5,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# Example Job Description\n","EXAMPLE_JD = \"\"\"\n","We are seeking a Backend Engineer with 3+ years of experience in Python, Django, REST APIs, and\n","cloud deployment (GCP or AWS). Experience with PostgreSQL and Docker is required. The candidate\n","will build scalable microservices and own features end-to-end.\n","\n","Required Skills:\n","- Python, Django, Flask\n","- REST API design\n","- PostgreSQL, Redis\n","- Docker, Kubernetes\n","- GCP or AWS\n","- Git, CI/CD\n","\n","Nice to have:\n","- Experience with microservices architecture\n","- Knowledge of GraphQL\n","- Frontend experience (React/Vue)\n","\"\"\""],"metadata":{"id":"IzwGLdI2HXK0","executionInfo":{"status":"ok","timestamp":1764601566721,"user_tz":-420,"elapsed":59,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Upload and analyze\n","if IN_COLAB:\n","    print(\"Upload your resume (PDF or DOCX):\")\n","    uploaded = files.upload()\n","\n","    if uploaded:\n","        resume_file = list(uploaded.keys())[0]\n","        print(f\"\\nAnalyzing: {resume_file}\\n\")\n","\n","        # Set your API key\n","        API_KEY = input(\"Enter your Google API Key: \")\n","\n","        # Run analysis\n","        results = analyze_resume(resume_file, EXAMPLE_JD, API_KEY)\n","\n","        # Display results\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"RESUME ANALYSIS RESULTS\")\n","        print(\"=\"*60)\n","\n","        print(\"\\n--- MODEL OUTPUTS ---\")\n","        print(f\"Predicted Role: {results['model_outputs']['predicted_role']}\")\n","        print(f\"Acceptance Probability: {results['model_outputs']['acceptance_probability']:.2%}\")\n","        print(f\"Similarity Score: {results['model_outputs']['similarity_score']:.3f}\")\n","        print(f\"Missing Keywords: {', '.join(results['model_outputs']['missing_keywords'][:10])}\")\n","\n","        print(\"\\n--- GEMINI ASSESSMENT ---\")\n","        assessment = results['gemini_assessment']\n","        print(f\"Overall Score: {assessment.get('score', 'N/A')}/100\")\n","        print(f\"\\nExplanation: {assessment.get('explanation', 'N/A')}\")\n","\n","        if 'revision_suggestions' in assessment:\n","            print(\"\\nRevision Suggestions:\")\n","            for i, suggestion in enumerate(assessment['revision_suggestions'], 1):\n","                print(f\"  {i}. {suggestion}\")\n","\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"\\nFull results saved in 'results' variable\")\n","\n","else:\n","    print(\"Not in Colab. Example usage:\")\n","    print(\"\"\"\n","    # Set your API key\n","    API_KEY = 'your-google-api-key'\n","\n","    # Analyze resume\n","    results = analyze_resume('path/to/resume.pdf', EXAMPLE_JD, API_KEY)\n","\n","    # Print results\n","    print(json.dumps(results['gemini_assessment'], indent=2))\n","    \"\"\")"],"metadata":{"id":"HSqqlK0VHbgi","colab":{"base_uri":"https://localhost:8080/","height":57},"executionInfo":{"status":"ok","timestamp":1764601618295,"user_tz":-420,"elapsed":51603,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}},"outputId":"5f05f996-acf4-4ab6-a22c-6a8dfde9fcc9"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload your resume (PDF or DOCX):\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a0a4ca58-d7f0-4049-8c3d-5cb6d821db09\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a0a4ca58-d7f0-4049-8c3d-5cb6d821db09\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]},{"cell_type":"code","source":["class ResumeAnalysisDebugger:\n","    \"\"\"Comprehensive debugging tools for the resume analysis pipeline.\"\"\"\n","\n","    def __init__(self, verbose=True):\n","        self.verbose = verbose\n","        self.logs = []\n","\n","    def log(self, message, level=\"INFO\"):\n","        \"\"\"Log a message with timestamp.\"\"\"\n","        import datetime\n","        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","        log_entry = f\"[{timestamp}] [{level}] {message}\"\n","        self.logs.append(log_entry)\n","        if self.verbose:\n","            print(log_entry)\n","\n","    def test_gemini_connection(self, api_key: str) -> bool:\n","        \"\"\"Test if Gemini API is accessible and working.\"\"\"\n","        self.log(\"Testing Gemini API connection...\")\n","        try:\n","            os.environ['GOOGLE_API_KEY'] = api_key\n","            llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=0.0)\n","            response = llm.invoke(\"Say 'connection successful'\")\n","            if response.content:\n","                self.log(\"Gemini API connection successful\", \"SUCCESS\")\n","                return True\n","        except Exception as e:\n","            self.log(f\"Gemini API connection failed: {str(e)}\", \"ERROR\")\n","            return False\n","\n","    def test_embedder_module(self) -> bool:\n","        \"\"\"Test if embedder module is properly loaded.\"\"\"\n","        self.log(\"Testing embedder module...\")\n","        try:\n","            test_text = [\"Hello world\", \"Test sentence\"]\n","            embeddings = embedder.encode(test_text, show_progress_bar=False)\n","            if embeddings.shape[0] == 2:\n","                self.log(f\"Embedder loaded successfully. Embedding dimension: {embeddings.shape[1]}\", \"SUCCESS\")\n","                return True\n","        except ImportError as e:\n","            self.log(f\"Cannot import embedder_module: {str(e)}\", \"ERROR\")\n","            self.log(\"Make sure embedder_module.py exists in the same directory\", \"ERROR\")\n","            return False\n","        except Exception as e:\n","            self.log(f\"Embedder error: {str(e)}\", \"ERROR\")\n","            return False\n","\n","    def test_file_scraping(self, file_path: str, api_key: str) -> Dict[str, Any]:\n","        \"\"\"Test file scraping functionality.\"\"\"\n","        self.log(f\"Testing file scraping for: {file_path}\")\n","        results = {\n","            'file_exists': False,\n","            'file_type': None,\n","            'scraping_successful': False,\n","            'text_length': 0,\n","            'error': None\n","        }\n","\n","        # Check file exists\n","        if not os.path.exists(file_path):\n","            results['error'] = \"File does not exist\"\n","            self.log(f\"File not found: {file_path}\", \"ERROR\")\n","            return results\n","\n","        results['file_exists'] = True\n","\n","        # Determine file type\n","        if file_path.lower().endswith('.pdf'):\n","            results['file_type'] = 'PDF'\n","        elif file_path.lower().endswith('.docx'):\n","            results['file_type'] = 'DOCX'\n","        else:\n","            results['error'] = \"Unsupported file type\"\n","            self.log(\"File must be PDF or DOCX\", \"ERROR\")\n","            return results\n","\n","        # Test scraping\n","        try:\n","            if results['file_type'] == 'PDF':\n","                text = scrape_pdf_with_gemini(file_path, api_key)\n","            else:\n","                text = scrape_docx_with_gemini(file_path, api_key)\n","\n","            results['scraping_successful'] = True\n","            results['text_length'] = len(text)\n","            self.log(f\"Successfully scraped {results['text_length']} characters\", \"SUCCESS\")\n","            self.log(f\"Preview: {text[:200]}...\", \"INFO\")\n","\n","        except Exception as e:\n","            results['error'] = str(e)\n","            self.log(f\"✗ Scraping failed: {str(e)}\", \"ERROR\")\n","\n","        return results\n","\n","    def test_models(self, sample_text: str = None) -> Dict[str, Any]:\n","        \"\"\"Test if ML models are working.\"\"\"\n","        self.log(\"Testing ML models...\")\n","\n","        if sample_text is None:\n","            sample_text = \"\"\"\n","            Experienced Software Engineer with 5 years in backend development.\n","            Proficient in Python, Django, PostgreSQL, and AWS.\n","            Led team of 3 developers in building scalable microservices.\n","            \"\"\"\n","\n","        results = {\n","            'role_prediction': None,\n","            'acceptance_prediction': None,\n","            'errors': []\n","        }\n","\n","        try:\n","            models = ResumeModels()\n","\n","            # Test role prediction\n","            try:\n","                role = models.predict_role(sample_text)\n","                results['role_prediction'] = role\n","                self.log(f\"Role prediction: {role}\", \"SUCCESS\")\n","            except Exception as e:\n","                results['errors'].append(f\"Role prediction error: {str(e)}\")\n","                self.log(f\"✗ Role prediction failed: {str(e)}\", \"ERROR\")\n","\n","            # Test acceptance prediction\n","            try:\n","                acceptance = models.predict_acceptance(sample_text)\n","                results['acceptance_prediction'] = acceptance\n","                self.log(f\"Acceptance prediction: {acceptance:.2%}\", \"SUCCESS\")\n","            except Exception as e:\n","                results['errors'].append(f\"Acceptance prediction error: {str(e)}\")\n","                self.log(f\"Acceptance prediction failed: {str(e)}\", \"ERROR\")\n","\n","        except Exception as e:\n","            results['errors'].append(f\"Model initialization error: {str(e)}\")\n","            self.log(f\"Model initialization failed: {str(e)}\", \"ERROR\")\n","\n","        return results\n","\n","    def test_similarity_computation(self) -> bool:\n","        \"\"\"Test embedding similarity computation.\"\"\"\n","        self.log(\"Testing similarity computation...\")\n","\n","        try:\n","          resume = \"Python developer with Django experience\"\n","          jd = \"Looking for Python Django developer\"\n","\n","          result = compute_resume_jd_similarity(resume, jd)\n","\n","          self.log(f\"Similarity score: {result['similarity_score']:.3f}\", \"SUCCESS\")\n","          self.log(f\"Missing keywords: {result['missing_keywords'][:5]}\", \"INFO\")\n","          return True\n","\n","        except Exception as e:\n","          self.log(f\"Similarity computation failed: {str(e)}\", \"ERROR\")\n","          return False\n","\n","    def test_gemini_assessment(self, api_key: str) -> bool:\n","        \"\"\"Test Gemini assessment with sample data.\"\"\"\n","        self.log(\"Testing Gemini assessment...\")\n","\n","        try:\n","          # resume\n","          sample_resume = \"Backend Engineer with Python, Django, PostgreSQL experience\"\n","\n","          # job description\n","          sample_jd = \"Looking for Backend Engineer with Python skills\"\n","\n","          assessment = get_gemini_assessment(\n","              resume_text=sample_resume,\n","              jd_text=sample_jd,\n","              predicted_role=\"Backend Engineer\",\n","              acceptance_prob=0.75,\n","              similarity_score=0.85,\n","              missing_keywords=[\"docker\", \"kubernetes\"],\n","              api_key=api_key\n","          )\n","\n","          if 'score' in assessment:\n","            self.log(f\"Gemini assessment successful. Score: {assessment['score']}/100\", \"SUCCESS\")\n","            return True\n","          else:\n","            self.log(\"Gemini assessment returned incomplete response\", \"ERROR\")\n","            return False\n","\n","        except Exception as e:\n","          self.log(f\"Gemini assessment failed: {str(e)}\", \"ERROR\")\n","          return False\n","\n","    def run_full_diagnostics(self, api_key: str, test_file_path: str = None) -> Dict[str, Any]:\n","        \"\"\"Run complete diagnostic tests on the entire pipeline.\"\"\"\n","        self.log(\"=\"*60, \"INFO\")\n","        self.log(\"STARTING FULL DIAGNOSTICS\", \"INFO\")\n","        self.log(\"=\"*60, \"INFO\")\n","\n","        results = {\n","            'gemini_connection': False,\n","            'embedder_module': False,\n","            'models': False,\n","            'similarity': False,\n","            'gemini_assessment': False,\n","            'file_scraping': None,\n","            'overall_status': 'FAILED'\n","        }\n","\n","        # Test 1: Gemini connection\n","        results['gemini_connection'] = self.test_gemini_connection(api_key)\n","\n","        # Test 2: Embedder module\n","        results['embedder_module'] = self.test_embedder_module()\n","\n","        # Test 3: ML models\n","        model_results = self.test_models()\n","        results['models'] = len(model_results['errors']) == 0\n","\n","        # Test 4: Similarity computation\n","        if results['embedder_module']:\n","            results['similarity'] = self.test_similarity_computation()\n","\n","        # Test 5: Gemini assessment\n","        if results['gemini_connection']:\n","            results['gemini_assessment'] = self.test_gemini_assessment(api_key)\n","\n","        # Test 6: File scraping (optional)\n","        if test_file_path and results['gemini_connection']:\n","            results['file_scraping'] = self.test_file_scraping(test_file_path, api_key)\n","\n","        # Overall status\n","        critical_tests = [\n","            results['gemini_connection'],\n","            results['embedder_module'],\n","            results['models']\n","        ]\n","\n","        if all(critical_tests):\n","            results['overall_status'] = 'PASSED'\n","            self.log(\"=\"*60, \"SUCCESS\")\n","            self.log(\"ALL CRITICAL TESTS PASSED\", \"SUCCESS\")\n","            self.log(\"=\"*60, \"SUCCESS\")\n","        else:\n","            self.log(\"=\"*60, \"ERROR\")\n","            self.log(\"SOME TESTS FAILED - CHECK LOGS ABOVE\", \"ERROR\")\n","            self.log(\"=\"*60, \"ERROR\")\n","\n","        return results\n","\n","    def save_logs(self, filename=\"debug_logs.txt\"):\n","        \"\"\"Save all logs to a file.\"\"\"\n","        with open(filename, 'w') as f:\n","            f.write('\\n'.join(self.logs))\n","        self.log(f\"Logs saved to {filename}\", \"INFO\")"],"metadata":{"id":"o7F11nc8Hp5W","executionInfo":{"status":"ok","timestamp":1764601618345,"user_tz":-420,"elapsed":31,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["debugger = ResumeAnalysisDebugger(verbose=True)\n","\n","debugger.test_gemini_connection(GOOGLE_API_KEY)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJWiQTaUSjXO","executionInfo":{"status":"ok","timestamp":1764603002560,"user_tz":-420,"elapsed":888,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}},"outputId":"955f5691-6f4b-4078-b128-860a71eb838f"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["[2025-12-01 15:30:02] [INFO] Testing Gemini API connection...\n","[2025-12-01 15:30:03] [SUCCESS] Gemini API connection successful\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["debugger.test_file_scraping('/content/example.pdf', GOOGLE_API_KEY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"LxMm4ImuTxQ2","executionInfo":{"status":"ok","timestamp":1764601632457,"user_tz":-420,"elapsed":12980,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}},"outputId":"5f207d79-edd5-4d2b-81b4-912f7ea0cd61"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["[2025-12-01 15:07:00] [INFO] Testing file scraping for: /content/example.pdf\n","[2025-12-01 15:07:13] [SUCCESS] Successfully scraped 5819 characters\n","[2025-12-01 15:07:13] [INFO] Preview: Here's the cleaned, organized, and structured resume based on the raw text provided:\n","\n","---\n","\n","**MUHAMMAD RAFFI AKHDILPUTRA**\n","Data Analyst | Data Science Enthusiast | Machine Learning Developer\n","\n","Jakarta S...\n"]},{"output_type":"execute_result","data":{"text/plain":["{'file_exists': True,\n"," 'file_type': 'PDF',\n"," 'scraping_successful': True,\n"," 'text_length': 5819,\n"," 'error': None}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["debugger.test_embedder_module()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"b63tXcVYU7Px","executionInfo":{"status":"ok","timestamp":1764601632505,"user_tz":-420,"elapsed":29,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}},"outputId":"7cca0ad1-81ae-42b7-9913-1e75fc6ab04b"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[2025-12-01 15:07:13] [INFO] Testing embedder module...\n","[2025-12-01 15:07:13] [SUCCESS] Embedder loaded successfully. Embedding dimension: 384\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["debugger.run_full_diagnostics(GOOGLE_API_KEY, '/content/example.pdf')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"LOnFoUlHbOkA","executionInfo":{"status":"ok","timestamp":1764601655407,"user_tz":-420,"elapsed":22885,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}},"outputId":"3ee75688-f483-4d23-b83b-51622888b1bb"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[2025-12-01 15:07:13] [INFO] ============================================================\n","[2025-12-01 15:07:13] [INFO] STARTING FULL DIAGNOSTICS\n","[2025-12-01 15:07:13] [INFO] ============================================================\n","[2025-12-01 15:07:13] [INFO] Testing Gemini API connection...\n","[2025-12-01 15:07:14] [SUCCESS] Gemini API connection successful\n","[2025-12-01 15:07:14] [INFO] Testing embedder module...\n","[2025-12-01 15:07:14] [SUCCESS] Embedder loaded successfully. Embedding dimension: 384\n","[2025-12-01 15:07:14] [INFO] Testing ML models...\n","[2025-12-01 15:07:14] [SUCCESS] Role prediction: Backend Engineer\n","[2025-12-01 15:07:14] [SUCCESS] Acceptance prediction: 100.00%\n","[2025-12-01 15:07:14] [INFO] Testing similarity computation...\n","[2025-12-01 15:07:14] [SUCCESS] Similarity score: 0.886\n","[2025-12-01 15:07:14] [INFO] Missing keywords: ['looking', 'for']\n","[2025-12-01 15:07:14] [INFO] Testing Gemini assessment...\n","[2025-12-01 15:07:22] [SUCCESS] Gemini assessment successful. Score: 82/100\n","[2025-12-01 15:07:22] [INFO] Testing file scraping for: /content/example.pdf\n","[2025-12-01 15:07:36] [SUCCESS] Successfully scraped 5819 characters\n","[2025-12-01 15:07:36] [INFO] Preview: Here's the cleaned, organized, and structured resume based on the raw text provided:\n","\n","---\n","\n","**MUHAMMAD RAFFI AKHDILPUTRA**\n","Data Analyst | Data Science Enthusiast | Machine Learning Developer\n","\n","Jakarta S...\n","[2025-12-01 15:07:36] [SUCCESS] ============================================================\n","[2025-12-01 15:07:36] [SUCCESS] ALL CRITICAL TESTS PASSED\n","[2025-12-01 15:07:36] [SUCCESS] ============================================================\n"]},{"output_type":"execute_result","data":{"text/plain":["{'gemini_connection': True,\n"," 'embedder_module': True,\n"," 'models': True,\n"," 'similarity': True,\n"," 'gemini_assessment': True,\n"," 'file_scraping': {'file_exists': True,\n","  'file_type': 'PDF',\n","  'scraping_successful': True,\n","  'text_length': 5819,\n","  'error': None},\n"," 'overall_status': 'PASSED'}"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":[],"metadata":{"id":"eKZI6YolcJmg","executionInfo":{"status":"ok","timestamp":1764601655446,"user_tz":-420,"elapsed":15,"user":{"displayName":"Muhammad Raffi Akhdilputra","userId":"18198245582156474892"}}},"execution_count":45,"outputs":[]}]}